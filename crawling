import sys
import os
import time
import random
from selenium import webdriver
from bs4 import BeautifulSoup as bs
import pandas as pd


#options = webdriver.ChromeOptions()
#options.add_argument('headless')

driver = webdriver.Chrome('C:\Users\USER\chromedriver')
driver.implicitly_wait(3)

keyword = '여행'
base_url = "https://m.cafe.naver.com/ArticleSearchList.nhn?search.query=" + keyword + "&search.menuid=&search.searchBy=1&search.sortBy=date&search.clubid=10186119&search.option=0&search.defaultValue=1"
driver.get(base_url)

for page_num in range(1,5):
    driver.find_element_by_xpath('//*[@id="moreButton"]').click()
    time.sleep(1)
    
article_list = driver.find_elements_by_css_selector('#articleList > ul > li:nth-child(1)')
#article_urls = [ i.get_arrtribute('href') for i in article_list ]

ar_list = []

for article in article_urls:
    try:
        driver.get(article)
        soup = bs(driver.page_source, 'html.parser')
        title = soup.select('h3')[0].get_text()
        #date = soup.select("span.date.font_l")[0].get_text()
        #content_tags = soup.select('#postContent')[0].select('p')
        #content = ' '.join([ tags.get_text() for tags in content_tags ])
        #ar_list.append({'title' : title, 'date' : date, 'content' : content})
        ar_list.append({'title' : title})
        
    except:
        pass

cafe_df = pd.DataFrame(ar_list)
cafe_df.to_csv('20190110.csv', index=False,encoding='utf-8')
